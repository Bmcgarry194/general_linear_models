{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear to Logistic regression\n",
    "![img](img/linear_vs_logistic_regression.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning goals\n",
    "\n",
    "You will be able to:\n",
    "* Describe the need for logistic regression\n",
    "* Describe the mathematics behind logistic regression\n",
    "* Interpret the parameters of a logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we know about linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What are the requirements for the variables types?\n",
    "- What assumptions do we have?\n",
    "- How do we interpret the coefficients?\n",
    "- What metrics do we use to evaluate our model?\n",
    "\n",
    "And how will logistic regression be different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scenarios "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Scenario 1: Predict income together\n",
    "In this example, we want to find a relationship between age and monthly income. It is definitely reasonable to assume that, on average, older people have a higher income than younger people who are newer to the job market and have less experience. A potential relationship could look like the plot below. The monthly income is shown in 1000 USD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Scenario 2: Predict likelihood of diabetes\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage. [reference here](https://www.kaggle.com/uciml/pima-indians-diabetes-database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# create data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "age = np.random.uniform(18, 65, 100)\n",
    "income = np.random.normal((age/10), 0.5)\n",
    "age = age.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "fig.suptitle('age vs income', fontsize=16)\n",
    "plt.scatter(age, income)\n",
    "plt.xlabel(\"age\", fontsize=14)\n",
    "plt.ylabel(\"monthly income\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In linear regression, you would try to find a relationship between age and monthly income. Conceptually, this means fitting a line that represents the relationship between age and monthly income, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "fig.suptitle('linear regression', fontsize=16)\n",
    "plt.scatter(age, income)\n",
    "plt.plot(age, age/10, c = \"black\")\n",
    "plt.xlabel(\"age\", fontsize=14)\n",
    "plt.ylabel(\"monthly income\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The idea is that you could use this line to make predictions in the future. In this case, the relationship is modeled as follows: the expected monthly income for someone who is, say, 40 years old, is 3000 (3 on the y-axis). Of course, the actual income will most likely be different, but this gives an indication of what the model predicts as the salary value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## So how is this related to logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, imagine you get a data set where no information on exact income is given (after all, people don't like to talk about how much they earn!), but you only have information on whether or not they earn more than 4000 USD per month. Starting from the generated data we used before, the new variable `income_bin` was transformed to 1 when someone's income is over 4000 USD, and 0 when the income is less than 4000 USD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "income_bin = income > 4\n",
    "income_bin =income_bin.astype(int)  \n",
    "print(income_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's have a look at what happens when we plot this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "fig.suptitle('age vs binary income', fontsize=16)\n",
    "plt.scatter(age, income_bin)\n",
    "plt.xlabel(\"age\", fontsize=14)\n",
    "plt.ylabel(\"monthly income (> or < 4000)\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can already tell that fitting a straight line will not be exactly desired here, but let's still have a look at what happens when you fit a regression line to these data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# create linear regression object\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(age, income_bin)\n",
    "# store the coefficients\n",
    "coef = lin_reg.coef_\n",
    "interc = lin_reg.intercept_\n",
    "# create the line\n",
    "lin_income = (interc + age * coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "fig.suptitle('linear regression', fontsize=16)\n",
    "plt.scatter(age, income_bin)\n",
    "plt.xlabel(\"age\", fontsize=14)\n",
    "plt.ylabel(\"monthly income\", fontsize=14)\n",
    "plt.plot(age, lin_income, c = \"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can see that this doesn't make a lot of sense. This straight line cannot grasp the true structure of what is going on when using a linear regression model. Now, without going into the mathematical details for now, let's look at a logistic regression model and fit that to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logistic regression object\n",
    "regr = LogisticRegression(C=1e5)\n",
    "# Train the model using the training sets\n",
    "regr.fit(age, income_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the coefficients\n",
    "coef = regr.coef_\n",
    "interc = regr.intercept_\n",
    "# create the linear predictor\n",
    "lin_pred= (age * coef + interc)\n",
    "# perform the log transformation\n",
    "mod_income = 1 / (1 + np.exp(-lin_pred))\n",
    "#sort the numbers to make sure plot looks right\n",
    "age_ordered, mod_income_ordered = zip(*sorted(zip(age ,mod_income.ravel()),key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Look at dataset predictions\n",
    "\n",
    "It is the **probability** of being in the target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "print(mod_income[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "fig.suptitle('logistic regression', fontsize=16)\n",
    "plt.scatter(age, income_bin)\n",
    "plt.xlabel(\"age\", fontsize=14)\n",
    "plt.ylabel(\"monthly income\", fontsize=14)\n",
    "plt.plot(age_ordered, mod_income_ordered, c = \"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Review the new shape\n",
    "\n",
    "This already looks a lot better! You can see that this function has an S-shape which plateaus to 0 in the left tale and 1 to the right tale. This is exactly what we needed here. Hopefully this example was a good way of showing why logistic regression is useful. Now, it's time to dive into the mathematics that make logistic regression possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That **S-shape** is what's known as a **sigmoid function**\n",
    "\n",
    "![sigmoid](img/SigmoidFunction_701.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logistic regression model formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might remember from the linear regression lesson, a linear regression model can be written as:\n",
    "\n",
    "$$ \\hat y = \\hat\\beta_0 + \\hat\\beta_1 x_1 + \\hat\\beta_2, x_2 +\\ldots + \\beta_n x_n $$\n",
    "\n",
    "When there are $n$ predictors $x_1,\\ldots,x_n$ and $n+1$ parameter estimates that are estimated by the model $\\hat\\beta_0, \\hat\\beta_1,\\ldots, \\hat\\beta_n$. $ \\hat y $ is an estimator for the outcome variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translating this model formulation to our example, this boils down to:\n",
    "\n",
    "$$ \\text{income} = \\beta_0 + \\beta_1 \\text{age} $$\n",
    "\n",
    "When you want to apply this to a binary dataset, what you actually want to do is perform a **classification** of your data in one group versus another one. In our case, we want to classify our observations (the 100 people in our data set) as good as possible in \"earns more than 4k\" and \"earns less than 4k\". A model will have to make a guess of what the **probability** is of belonging to one group versus another. And that is exactly what logistic regression models can do! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation\n",
    "\n",
    "Essentially, what happens is, the linear regression is *transformed* in a way that the outcome takes a value between 0 and 1. This can then be interpreted as a probability (e.g., 0.2 is a probability of 20%). Applied to our example, the expression for a logistic regression model would look like this:\n",
    "\n",
    "$$ P(\\text{income} > 4000) = \\displaystyle \\frac{1}{1+e^{-(\\hat \\beta_0+\\hat \\beta_1 \\text{age})}}$$\n",
    "\n",
    "Note that the outcome is written as $P(\\text{income} > 4000)$. This means that the output should be interpreted as *the probability that the monthly income is over 4000 USD*.\n",
    "\n",
    "It is important to note that this is the case because the income variable was relabeled to be equal to 1 when the income is bigger than 4000, and 0 when smaller than 4000. In other words, The outcome variable should be interpreted as *the* **probability** *of the class label to be equal to 1*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interpretation - with a side of more math\n",
    "#### What are the odds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As mentioned before, the probability of an income over 4000 can be calculated using:\n",
    "\n",
    "$$ P(\\text{income} > 4000) = \\displaystyle \\frac{1}{1+e^{-(\\hat \\beta_o+\\hat \\beta_1 \\text{age})}}$$\n",
    "\n",
    "You can show that, by multiplying both numerator and denominator by $e^{(\\hat \\beta_0+\\hat \\beta_1 \\text{age})}$\n",
    "\n",
    "\n",
    "$$ P(\\text{income} > 4000) = \\displaystyle \\frac{e^{\\hat \\beta_0+\\hat \\beta_1 \\text{age}}}{1+e^{\\hat \\beta_o+\\hat \\beta_1 \\text{age}}}$$\n",
    "\n",
    "As a result, you can compute $P(\\text{income} \\leq 4000)$ as:\n",
    "\n",
    "$$ P(\\text{income} < 4000) = 1- \\displaystyle \\frac{e^{\\hat \\beta_0+\\hat \\beta_1 \\text{age}}}{1+e^{\\hat \\beta_o+\\hat \\beta_1 \\text{age}}}= \\displaystyle \\frac{1}{1+e^{\\hat \\beta_0+\\hat \\beta_1 \\text{age}}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Odds ratio\n",
    "\n",
    "This doesn't seem to be very spectacular, but combining these two results leads to an easy interpretation of the model parameters, triggered by the *odds*\n",
    "\n",
    "$$ \\dfrac{P(\\text{income} > 4000)}{P(\\text{income} < 4000)} = e^{\\hat \\beta_0+\\hat \\beta_1 \\text{age}} $$\n",
    "\n",
    "This expression can be interpreted as the *odds in favor of an income greater than 4000 USD*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Interpretting coefficients\n",
    "\n",
    "This result, in combination with mathematical properties of exponential functions, leads to the fact that, applied to our example:\n",
    "\n",
    "if *age* goes up by 1, the odds are multiplied by $e^{\\beta_1}$\n",
    "\n",
    "In our example, there is a positive relationship between age and income, this will lead a positive $\\beta_1 > 0$, so $e^{\\beta_1}>1$, and the odds will increase as *age* increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions\n",
    "\n",
    "- Binary logistic regression requires the dependent variable to be binary.\n",
    "- For a binary regression, the factor level 1 of the dependent variable should represent the desired outcome.\n",
    "- Only the meaningful variables should be included.\n",
    "- The independent variables should be independent of each other. That is, the model should have little or no multicollinearity.\n",
    "- The independent variables are linearly related to the log odds.\n",
    "- Logistic regression requires quite large sample sizes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
